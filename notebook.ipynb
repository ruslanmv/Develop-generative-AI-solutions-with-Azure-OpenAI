{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings, but I'm functioning properly and ready to assist you with any queries or tasks you have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "# Create chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response from the AI model\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9YZMZo3ApQI8OBcfchv9L7I19UOBG\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Microsoft was founded by Bill Gates and Paul Allen in April 1975. Bill Gates, who is widely known as one of the most successful entrepreneurs in the tech industry, served as the company's chairman and CEO until 2000. Paul Allen, who sadly passed away in 2018, played a significant role in the early development of Microsoft and co-founded the company with Gates.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1718026115,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 77,\n",
      "    \"prompt_tokens\": 29,\n",
      "    \"total_tokens\": 106\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Microsoft was founded by Bill Gates and Paul Allen in April 1975. Bill Gates, who is widely known as one of the most successful entrepreneurs in the tech industry, served as the company's chairman and CEO until 2000. Paul Allen, who sadly passed away in 2018, played a significant role in the early development of Microsoft and co-founded the company with Gates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "#print(response)\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9YZe2oiv45D2u4Rqq7OHRZLUf0oPt\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"There doesn't seem to be a commonly known organization or individual referred to as \\\"DRI\\\" specifically in relation to an opinion mining service. It's possible that \\\"DRI\\\" could be a reference to a company or individual operating in a specific industry or context that provides opinion mining services, but without more specific information, it is difficult to determine the exact entity in question.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1718027198,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 75,\n",
      "    \"prompt_tokens\": 43,\n",
      "    \"total_tokens\": 118\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "There doesn't seem to be a commonly known organization or individual referred to as \"DRI\" specifically in relation to an opinion mining service. It's possible that \"DRI\" could be a reference to a company or individual operating in a specific industry or context that provides opinion mining services, but without more specific information, it is difficult to determine the exact entity in question.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is DRI?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"DRI stands for Directly Responsible Individual of a service. Which service are you asking about?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Opinion mining service\"\n",
    "        }\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#print(response)\n",
    "print(completion.model_dump_json(indent=2))\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Main  Function \n",
    "\n",
    "\n",
    "Let us build a simple `main` function that is an entry point for a program that interacts with the Azure OpenAI service. It takes a function as an argument, which will be called with the Azure OpenAI client and model.\n",
    "\n",
    "H\n",
    "\n",
    "1. **Initialization**: The function starts by loading environment variables using `load_dotenv()`.\n",
    "2. **Azure OpenAI Configuration**: The function retrieves three environment variables:\n",
    "\t* `AZURE_OAI_ENDPOINT`: the endpoint URL for the Azure OpenAI service\n",
    "\t* `AZURE_OAI_KEY`: the API key for the Azure OpenAI service\n",
    "\t* `AZURE_OAI_MODEL`: the model identifier for the Azure OpenAI service\n",
    "3. **Azure OpenAI Client Creation**: The function creates an instance of the `AzureOpenAI` client, passing in the endpoint URL, API key, and API version (`0613`).\n",
    "4. **Function Call**: The function checks if the passed argument `func` is a callable function using the `callable` function. If it is, the function calls the passed function with the Azure OpenAI client and model as arguments.\n",
    "5. **Error Handling**: The function catches any exceptions that may occur during execution and prints the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import utils\n",
    "# Add OpenAI import. (Added code)\n",
    "from openai import AzureOpenAI, Model, ChatCompletion\n",
    "def main(func):\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        utils.initLogFile()\n",
    "        azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "        azure_oai_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "        azure_oai_model = os.getenv(\"AZURE_OAI_MODEL\")\n",
    "        # Define Azure OpenAI client (Add code here)\n",
    "        client = AzureOpenAI(azure_endpoint=azure_oai_endpoint, api_key=azure_oai_key, api_version=\"2024-02-01\")\n",
    "        if callable(func):\n",
    "            func(client, azure_oai_model)\n",
    "        else:\n",
    "            print(\"Invalid input. Please pass a valid function.\")\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Implementing a Proof of Concept (PoC) for Azure OpenAI\n",
    "\n",
    "In this scenario, we're tasked with deploying a GPT-35-turbo-16k model in Azure OpenAI and configuring a sample application to connect to the resources. This serves as our initial PoC to demonstrate the capabilities of Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Validate PoC\n",
    "def function1(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 1: Validate PoC\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Modified code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText}  # Modified to us\"user\" role and \"content\" key\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,  # Added model parameter\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "    # Call chat completion connection. (Modified code)\n",
    "\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: hello\n",
      "\n",
      "Response: Hello! How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Developing the PoC App for Company Chatbot\n",
    "\n",
    "Here, we'll further develop the PoC app to explore the potential of Azure OpenAI for company chatbot functionality. The goal is to develop an app that provides responses in a casual tone, limited to 1,000 tokens, and with a temperature of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Company chatbot\n",
    "def function2(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 2: Company chatbot\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText},\n",
    "        {\"role\": \"assistant\", \"content\": \"You can find it on the footer of every page on our website. Hope that helps! Thanks for using Contoso, Ltd.\"}\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection. (Modified code)\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response\"+ response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "ResponseA generative AI model can create new content, such as text, images, or music, based on patterns and examples it has been trained on.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Using the PoC App for Developer Tasks\n",
    "\n",
    "In this scenario, we'll use the PoC app to assist with developer tasks such as code refactoring and unit testing. This demonstrates how Azure OpenAI can enhance productivity and streamline development workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Developer tasks\n",
    "def function3(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 3: Developer tasks\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}  # Initialize response content\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,  # Set temperature to 0.5\n",
    "        \"max_tokens\": 1000  # Set max tokens to 1000\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection. (Modified code)\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    \n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "Response: A generative AI model can create new and original content, such as text, images, music, and even videos, based on patterns and examples it has learned from.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Using Company Data for Travel Recommendations\n",
    "\n",
    "Finally, we'll extend the PoC app to utilize our company's data to better answer customer questions related to travel. The goal is to connect the PoC app to an Azure AI Search resource that contains sample travel data, providing more accurate and relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Use company data\n",
    "def function4(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 4: Use company data\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful travel agent.\"},\n",
    "        {\"role\": \"user\", \"content\": inputText}\n",
    "    ]\n",
    "    \n",
    "    # Define connection and argument list (Added code)\n",
    "    from azure.ai.search import SearchClient\n",
    "    from azure.ai.search.models import QueryType\n",
    "    search_client = SearchClient(\"https://search41431948.search.windows.net/\", \"pocindex\")\n",
    "    apiParams = {\n",
    "        \"search_client\": search_client,\n",
    "        \"query\": inputText,\n",
    "        \"query_type\": QueryType.KEYWORD\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "    \n",
    "    # Call search connection. (Added code)\n",
    "    response = search_client.search(**apiParams)\n",
    "    \n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.results[0].text + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "search_api_key = os.getenv(\"SEARCH_API_KEY\") #\"<your_search_api_key>\"\n",
    "blob_storage_connection_string =os.getenv(\"CONNECTION_STRING\") #\"<your_blob_storage_connection_string>\"\n",
    "def function4(aiClient, aiModel):\n",
    "    # Assuming you have the necessary Azure SDK installed and configured\n",
    "\n",
    "    # Load configuration file or define connection strings\n",
    "    search_service_name = \"search41431948\"\n",
    "    index_name = \"pocindex\"\n",
    "    search_api_key =search_api_key #\"<your_search_api_key>\"\n",
    "    blob_container_name = \"sa41431948\"\n",
    "    blob_storage_connection_string =blob_storage_connection_string #\"<your_blob_storage_connection_string>\"\n",
    "\n",
    "    # Initialize Azure Search client\n",
    "    search_client = SearchClient(account_url=f\"https://{search_service_name}.search.windows.net/\",\n",
    "                                 index_name=index_name,\n",
    "                                 credential=AzureKeyCredential(search_api_key))\n",
    "\n",
    "    inputText = utils.getPromptInput(\"Task 4: Use company data\", \"sample-text.txt\")\n",
    "\n",
    "    # Build messages to send to Azure OpenAI model\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText}\n",
    "    ]\n",
    "\n",
    "    # Define argument list\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,  # Set temperature to 0.5\n",
    "        \"max_tokens\": 1000  # Set max tokens to 1000\n",
    "    }\n",
    "\n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection.\n",
    "    response = aiClient.chat.completions.create(**apiParams)\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "\n",
    "    # Extract the user's query\n",
    "    user_query = response.choices[0].message.content\n",
    "\n",
    "    # Perform search on Azure AI Search\n",
    "    search_result = search_client.search(search_text=user_query, top=1)\n",
    "\n",
    "    if search_result:\n",
    "        # Extract the first result\n",
    "        first_result = search_result[0]\n",
    "\n",
    "        # Extract the system message\n",
    "        system_message = \"You are a helpful travel agent.\"\n",
    "\n",
    "        # Build the response message\n",
    "        response_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{system_message} {first_result['your_desired_field']}\"  # Update 'your_desired_field' to your desired field from the search result\n",
    "        }\n",
    "\n",
    "        # Append the response message to the messages list\n",
    "        messages.append(response_message)\n",
    "\n",
    "        # Update apiParams with new messages\n",
    "        apiParams['messages'] = messages\n",
    "\n",
    "        # Call chat completion connection again with updated messages\n",
    "        response = aiClient.chat.completions.create(**apiParams)\n",
    "        utils.writeLog(\"Response:\\n\", str(response))\n",
    "        print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    else:\n",
    "        print(\"No search result found.\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "No module named 'azure'\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "azure_oai_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "azure_oai_model = os.getenv(\"AZURE_OAI_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "deployment_name = 'tz-edu-gpt-35-turbo' \n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=\"2024-02-01\" #  Target version of the API, such as 2024-02-15-preview\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Azure OpenAI resource\n",
    "Once you've configured your connection to Azure OpenAI, send your prompt to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mdeployment_name,\n\u001b[0;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      4\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      5\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Azure OpenAI?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      6\u001b[0m     ]\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rusla\\.conda\\envs\\azure\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rusla\\.conda\\envs\\azure\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:606\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    608\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    609\u001b[0m             {\n\u001b[0;32m    610\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    611\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    612\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    613\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    614\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    615\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    616\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    617\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    618\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    620\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    621\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    622\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    623\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    625\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    626\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    627\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    628\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    629\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    630\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    631\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    632\u001b[0m             },\n\u001b[0;32m    633\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    634\u001b[0m         ),\n\u001b[0;32m    635\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    636\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    637\u001b[0m         ),\n\u001b[0;32m    638\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    639\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    640\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rusla\\.conda\\envs\\azure\\Lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\rusla\\.conda\\envs\\azure\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    922\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    923\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    924\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    925\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    926\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    927\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rusla\\.conda\\envs\\azure\\Lib\\site-packages\\openai\\_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1028\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure OpenAI?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = response.choices[0].message.content\n",
    "\n",
    "# Print the response\n",
    "print(\"Response: \" + generated_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response object contains several values, such as total_tokens and finish_reason. The completion from the response object will be similar to the following completion:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
