{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings, but I'm functioning properly and ready to assist you with any queries or tasks you have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "# Create chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response from the AI model\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9YZMZo3ApQI8OBcfchv9L7I19UOBG\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Microsoft was founded by Bill Gates and Paul Allen in April 1975. Bill Gates, who is widely known as one of the most successful entrepreneurs in the tech industry, served as the company's chairman and CEO until 2000. Paul Allen, who sadly passed away in 2018, played a significant role in the early development of Microsoft and co-founded the company with Gates.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1718026115,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 77,\n",
      "    \"prompt_tokens\": 29,\n",
      "    \"total_tokens\": 106\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Microsoft was founded by Bill Gates and Paul Allen in April 1975. Bill Gates, who is widely known as one of the most successful entrepreneurs in the tech industry, served as the company's chairman and CEO until 2000. Paul Allen, who sadly passed away in 2018, played a significant role in the early development of Microsoft and co-founded the company with Gates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "#print(response)\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9YZe2oiv45D2u4Rqq7OHRZLUf0oPt\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"There doesn't seem to be a commonly known organization or individual referred to as \\\"DRI\\\" specifically in relation to an opinion mining service. It's possible that \\\"DRI\\\" could be a reference to a company or individual operating in a specific industry or context that provides opinion mining services, but without more specific information, it is difficult to determine the exact entity in question.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1718027198,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 75,\n",
      "    \"prompt_tokens\": 43,\n",
      "    \"total_tokens\": 118\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "There doesn't seem to be a commonly known organization or individual referred to as \"DRI\" specifically in relation to an opinion mining service. It's possible that \"DRI\" could be a reference to a company or individual operating in a specific industry or context that provides opinion mining services, but without more specific information, it is difficult to determine the exact entity in question.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# Set environment variables\n",
    "endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\") \n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=\"2024-02-01\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is DRI?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"DRI stands for Directly Responsible Individual of a service. Which service are you asking about?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Opinion mining service\"\n",
    "        }\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#print(response)\n",
    "print(completion.model_dump_json(indent=2))\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Main  Function \n",
    "\n",
    "\n",
    "Let us build a simple `main` function that is an entry point for a program that interacts with the Azure OpenAI service. It takes a function as an argument, which will be called with the Azure OpenAI client and model.\n",
    "\n",
    "H\n",
    "\n",
    "1. **Initialization**: The function starts by loading environment variables using `load_dotenv()`.\n",
    "2. **Azure OpenAI Configuration**: The function retrieves three environment variables:\n",
    "\t* `AZURE_OAI_ENDPOINT`: the endpoint URL for the Azure OpenAI service\n",
    "\t* `AZURE_OAI_KEY`: the API key for the Azure OpenAI service\n",
    "\t* `AZURE_OAI_MODEL`: the model identifier for the Azure OpenAI service\n",
    "3. **Azure OpenAI Client Creation**: The function creates an instance of the `AzureOpenAI` client, passing in the endpoint URL, API key, and API version (`0613`).\n",
    "4. **Function Call**: The function checks if the passed argument `func` is a callable function using the `callable` function. If it is, the function calls the passed function with the Azure OpenAI client and model as arguments.\n",
    "5. **Error Handling**: The function catches any exceptions that may occur during execution and prints the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import utils\n",
    "# Add OpenAI import. (Added code)\n",
    "from openai import AzureOpenAI, Model, ChatCompletion\n",
    "def main(func):\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        utils.initLogFile()\n",
    "        azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "        azure_oai_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "        azure_oai_model = os.getenv(\"AZURE_OAI_MODEL\")\n",
    "        # Define Azure OpenAI client (Add code here)\n",
    "        client = AzureOpenAI(azure_endpoint=azure_oai_endpoint, api_key=azure_oai_key, api_version=\"2024-02-01\")\n",
    "        if callable(func):\n",
    "            func(client, azure_oai_model)\n",
    "        else:\n",
    "            print(\"Invalid input. Please pass a valid function.\")\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Implementing a Proof of Concept (PoC) for Azure OpenAI\n",
    "\n",
    "In this scenario, we're tasked with deploying a GPT-35-turbo-16k model in Azure OpenAI and configuring a sample application to connect to the resources. This serves as our initial PoC to demonstrate the capabilities of Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Validate PoC\n",
    "def function1(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 1: Validate PoC\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Modified code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText}  # Modified to us\"user\" role and \"content\" key\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,  # Added model parameter\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "    # Call chat completion connection. (Modified code)\n",
    "\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: hello\n",
      "\n",
      "Response: Hello! How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Developing the PoC App for Company Chatbot\n",
    "\n",
    "Here, we'll further develop the PoC app to explore the potential of Azure OpenAI for company chatbot functionality. The goal is to develop an app that provides responses in a casual tone, limited to 1,000 tokens, and with a temperature of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Company chatbot\n",
    "def function2(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 2: Company chatbot\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText},\n",
    "        {\"role\": \"assistant\", \"content\": \"You can find it on the footer of every page on our website. Hope that helps! Thanks for using Contoso, Ltd.\"}\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection. (Modified code)\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response\"+ response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "ResponseA generative AI model can create new content, such as text, images, or music, based on patterns and examples it has been trained on.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Using the PoC App for Developer Tasks\n",
    "\n",
    "In this scenario, we'll use the PoC app to assist with developer tasks such as code refactoring and unit testing. This demonstrates how Azure OpenAI can enhance productivity and streamline development workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Developer tasks\n",
    "def function3(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 3: Developer tasks\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}  # Initialize response content\n",
    "    ]\n",
    "    \n",
    "    # Define argument list (Modified code)\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,  # Set temperature to 0.5\n",
    "        \"max_tokens\": 1000  # Set max tokens to 1000\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection. (Modified code)\n",
    "    response = aiClient.chat.completions.create(**apiParams) # Modified to use the aiClient and **apiParams\n",
    "    \n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "Response: A generative AI model can create new and original content, such as text, images, music, and even videos, based on patterns and examples it has learned from.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Using Company Data for Travel Recommendations\n",
    "\n",
    "Finally, we'll extend the PoC app to utilize our company's data to better answer customer questions related to travel. The goal is to connect the PoC app to an Azure AI Search resource that contains sample travel data, providing more accurate and relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "search_api_key = os.getenv(\"SEARCH_API_KEY\") #\"<your_search_api_key>\"\n",
    "blob_storage_connection_string =os.getenv(\"CONNECTION_STRING\") #\"<your_blob_storage_connection_string>\"\n",
    "def function4(aiClient, aiModel):\n",
    "    # Assuming you have the necessary Azure SDK installed and configured\n",
    "\n",
    "    # Load configuration file or define connection strings\n",
    "    search_service_name = \"search41431948\"\n",
    "    index_name = \"pocindex\"\n",
    "    search_api_key =search_api_key #\"<your_search_api_key>\"\n",
    "    blob_container_name = \"sa41431948\"\n",
    "    blob_storage_connection_string =blob_storage_connection_string #\"<your_blob_storage_connection_string>\"\n",
    "\n",
    "    # Initialize Azure Search client\n",
    "    search_client = SearchClient(account_url=f\"https://{search_service_name}.search.windows.net/\",\n",
    "                                 index_name=index_name,\n",
    "                                 credential=AzureKeyCredential(search_api_key))\n",
    "\n",
    "    inputText = utils.getPromptInput(\"Task 4: Use company data\", \"sample-text.txt\")\n",
    "\n",
    "    # Build messages to send to Azure OpenAI model\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": inputText}\n",
    "    ]\n",
    "\n",
    "    # Define argument list\n",
    "    apiParams = {\n",
    "        \"model\": aiModel,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5,  # Set temperature to 0.5\n",
    "        \"max_tokens\": 1000  # Set max tokens to 1000\n",
    "    }\n",
    "\n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "\n",
    "    # Call chat completion connection.\n",
    "    response = aiClient.chat.completions.create(**apiParams)\n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "\n",
    "    # Extract the user's query\n",
    "    user_query = response.choices[0].message.content\n",
    "\n",
    "    # Perform search on Azure AI Search\n",
    "    search_result = search_client.search(search_text=user_query, top=1)\n",
    "\n",
    "    if search_result:\n",
    "        # Extract the first result\n",
    "        first_result = search_result[0]\n",
    "\n",
    "        # Extract the system message\n",
    "        system_message = \"You are a helpful travel agent.\"\n",
    "\n",
    "        # Build the response message\n",
    "        response_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{system_message} {first_result['your_desired_field']}\"  # Update 'your_desired_field' to your desired field from the search result\n",
    "        }\n",
    "\n",
    "        # Append the response message to the messages list\n",
    "        messages.append(response_message)\n",
    "\n",
    "        # Update apiParams with new messages\n",
    "        apiParams['messages'] = messages\n",
    "\n",
    "        # Call chat completion connection again with updated messages\n",
    "        response = aiClient.chat.completions.create(**apiParams)\n",
    "        utils.writeLog(\"Response:\\n\", str(response))\n",
    "        print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "    else:\n",
    "        print(\"No search result found.\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to type a prompt or text in file sample-text.txt? (type/file)\n",
      "...Reading text from sample-text.txt...\n",
      "\n",
      "\n",
      "...Sending the following request to Azure OpenAI...\n",
      "Request: What can a generative AI model do? Give me a short answer.\n",
      "\n",
      "No module named 'azure'\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with function1 as an argument\n",
    "main(function4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Azure OpenAI resource\n",
    "Once you've configured your connection to Azure OpenAI, send your prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "azure_oai_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "azure_oai_model = os.getenv(\"AZURE_OAI_MODEL\")\n",
    "from openai import AzureOpenAI\n",
    "deployment_name = 'tz-edu-gpt-35-turbo' \n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=\"2024-02-01\" #  Target version of the API, such as 2024-02-15-preview\n",
    "        )\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure OpenAI?\"}\n",
    "    ]\n",
    ")\n",
    "generated_text = response.choices[0].message.content\n",
    "# Print the response\n",
    "print(\"Response: \" + generated_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Use company data\n",
    "def function4(aiClient, aiModel):\n",
    "    inputText = utils.getPromptInput(\"Task 4: Use company data\", \"sample-text.txt\")\n",
    "    \n",
    "    # Build messages to send to Azure OpenAI model. (Added code)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful travel agent.\"},\n",
    "        {\"role\": \"user\", \"content\": inputText}\n",
    "    ]\n",
    "    \n",
    "    # Define connection and argument list (Added code)\n",
    "    from azure.ai.search import SearchClient\n",
    "    from azure.ai.search.models import QueryType\n",
    "    search_client = SearchClient(\"https://search41431948.search.windows.net/\", \"pocindex\")\n",
    "    apiParams = {\n",
    "        \"search_client\": search_client,\n",
    "        \"query\": inputText,\n",
    "        \"query_type\": QueryType.KEYWORD\n",
    "    }\n",
    "    \n",
    "    utils.writeLog(\"API Parameters:\\n\", apiParams)\n",
    "    \n",
    "    # Call search connection. (Added code)\n",
    "    response = search_client.search(**apiParams)\n",
    "    \n",
    "    utils.writeLog(\"Response:\\n\", str(response))\n",
    "    print(\"Response: \" + response.results[0].text + \"\\n\")\n",
    "    return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
